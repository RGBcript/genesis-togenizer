# ğŸ§¬ MAINI - Modular Artificial Intelligence Neural Infrastructure

> A biologically-inspired AGI architecture built on atomic information units (ToGens) and State Space Models (Mamba).

## ğŸŒŸ Overview

MAINI implements a novel approach to artificial general intelligence based on:

- **ToGen (128-bit Atomic Units)**: Fundamental information carriers inspired by physical atoms
- **Mamba SSM (State Space Model)**: World Model with O(n) complexity replacing attention
- **Predictive Processing**: Free Energy Principle / Karl Friston's theories
- **Atomic Flow**: Process information atom-by-atom, biologically correct

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MAINI                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ToGen  â”‚â”€â”€â–¶â”‚  Curo   â”‚â”€â”€â–¶â”‚ Genulse â”‚â”€â”€â–¶â”‚Arcodularâ”‚     â”‚
â”‚  â”‚ (Atom)  â”‚   â”‚ (Brain) â”‚   â”‚  (GPU)  â”‚   â”‚(Memory) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â”‚             â”‚             â”‚             â”‚           â”‚
â”‚       â–¼             â–¼             â–¼             â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Genesis Runtime                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Crates

### `togen` - The Atomic Unit
128-bit information atom with sub-atomic structure:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Header â”‚  Quantized   â”‚  Space  â”‚  Time   â”‚  Force  â”‚
â”‚  8-bit â”‚    48-bit    â”‚  16-bit â”‚  16-bit â”‚  16-bit â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **MATERIA**: Physical/sensory information
- **NO_MATERIA**: Abstract/conceptual information

### `curo` - The Brain (World Model)
Mamba-based State Space Model for predictive processing:
- **d_model**: 128 dimensions
- **n_layers**: 3 Mamba blocks
- **togen_proj**: Atom encoder (4 â†’ 128)
- **togen_out**: Atom decoder (128 â†’ 4)
- **Surprise tracking**: Prediction error history

### `genulse` - GPU Computation Engine
WGPU-based parallel processing for:
- Materia (visual/sensory) encoding
- Real-time inference
- Shader-based computation

### `arcodular` - Memory System
External memory and knowledge storage:
- Episodic memory
- Semantic knowledge graphs
- ONNX model integration

### `genesis_runtime` - Orchestrator
Main runtime coordinating all components.

### `inmece` - Internal Mechanism
Introspection and internal state management.

## ğŸš€ Quick Start

### Prerequisites
- Rust 1.75+
- Python 3.10+ (for training)
- CUDA/ROCm (optional, for GPU)

### Build
```bash
cd MAINI
cargo build --release
```

### Train Atomic Model
```bash
# 1. Prepare atomic dataset from videos
cd training
python prepare_atomic_dataset.py

# 2. Train Curo (Mamba World Model)
cargo run --release --bin train_atomic -p curo

# 3. Visualize atomic dreams
python visualize_atomic_dream.py
```

## ğŸ“‚ Project Structure

```
MAINI/
â”œâ”€â”€ Cargo.toml              # Workspace config
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ models/             # ONNX models
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ arcodular/          # Memory system
â”‚   â”œâ”€â”€ curo/               # Brain (Mamba SSM)
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ lib.rs
â”‚   â”‚       â”œâ”€â”€ model.rs    # CuroModel + MambaBlock
â”‚   â”‚       â”œâ”€â”€ config.rs
â”‚   â”‚       â””â”€â”€ bin/
â”‚   â”‚           â””â”€â”€ train_atomic.rs
â”‚   â”œâ”€â”€ genesis_runtime/    # Main runtime
â”‚   â”œâ”€â”€ genulse/            # GPU engine
â”‚   â”œâ”€â”€ inmece/             # Internal mechanism
â”‚   â””â”€â”€ togen/              # Atomic unit
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ lib.rs      # ToGen struct
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ RESEARCH_PHILOSOPHY.md
â””â”€â”€ training/
    â”œâ”€â”€ prepare_atomic_dataset.py
    â”œâ”€â”€ train_autoencoder.py
    â”œâ”€â”€ visualize_atomic_dream.py
    â””â”€â”€ README_TRAINING.md
```

## ğŸ§  Core Concepts

### Atomic Flow
Information flows atom-by-atom through the system:
```
Sensory Input â†’ ToGen atoms â†’ Mamba processing â†’ Prediction â†’ Action
```

### Predictive Processing
The brain constantly predicts the next atom:
- **Prediction**: What atom comes next?
- **Surprise**: Difference between prediction and reality
- **Learning**: Minimize surprise (Free Energy)

### State Space Model (Mamba)
Unlike Transformers with O(nÂ²) attention:
- **Linear complexity**: O(n)
- **Continuous state**: h(t) = AÂ·h(t-1) + BÂ·x(t)
- **Selective mechanism**: Learn what to remember

## ğŸ“Š Training Results

Atomic training on video data:
- **Loss**: 5.36 â†’ 0.38 (14x reduction)
- **Atoms generated**: 60 per dream
- **Force diversity**: 51 unique spatial values

## ğŸ”¬ Research Philosophy

MAINI is based on several theoretical foundations:
- **Free Energy Principle** (Karl Friston)
- **Predictive Coding** (Rao & Ballard)
- **State Space Models** (Mamba, S4)
- **Atomic Information Theory** (Original)

See [docs/RESEARCH_PHILOSOPHY.md](docs/RESEARCH_PHILOSOPHY.md) for details.

## ğŸ“œ License

MIT License - See LICENSE file

## ğŸ¤ Contributing

Contributions welcome! Please read the research philosophy first.

---

*"Intelligence is prediction. Prediction is compression. Compression is understanding."*
